\begin{frame}
  \frametitle{Feature importance}
  \begin{itemize}
    \item Many ways to define \emph{importance}
    \item Permutation Feature Importance (PFI) measures the accuracy drop if we permute a feature
  \end{itemize}

  \noindent\makebox[\linewidth]{\rule{\paperwidth}{0.4pt}}

  Algorithm:
  \begin{itemize}
    \item Estimate the original model error $e_{orig} = L(y,f(X))$
    \item For each feature $ d \in \{1, \ldots D\}$
    \begin{itemize}
      \item Generate feature matrix $X_{perm}$ by permuting feature $d$ in the data $X$
      \item Estimate error $e_{perm} = L(y,f(X_{perm}))$
      \item Calculate permutation feature importance as quotient $FI_d = \frac{e_{perm}}{e_orig}$ or $FI_d = e_{orig} - e_{perm}$
    \end{itemize}
  \end{itemize}

\end{frame}


\begin{frame}
  \frametitle{Permutation Feature Importance (PFI)}
  \begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{pfi}
    \caption{Image taken from \href{https://christophm.github.io/interpretable-ml-book/feature-importance.html}{Interpretable Machine Learning}}
  \end{figure}
\end{frame}


\begin{frame}
  \frametitle{Challenges/ideas for feature importance}
  \begin{itemize}
    \item Other ideas:
    \begin{itemize}
      \item Connection with feature effect
      \item $\mathtt{FI}_s = \int_{x_s} f_s(x_s)$, i.e.~energy of the signal
    \end{itemize}
    \item Challenges:
    \begin{itemize}
      \item Just permute the feature and measure the accuracy or retrain on the permuted dataset?
      \item If just permute, two highly correlated features may divide their importance (seem less important)
      \item If just permute, we suffer from unrealistic instances
      \item If retrain, two highly correlated features may cover each other (seem unimportant)
    \end{itemize}
  \end{itemize}
\end{frame}



