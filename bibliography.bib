@inproceedings{NIPS2015_a284df11,
 author = {Meeds, Ted and Welling, Max},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Optimization Monte Carlo: Efficient and Embarrassingly Parallel Likelihood-Free Inference},
 url = {https://proceedings.neurips.cc/paper/2015/file/a284df1155ec3e67286080500df36a9a-Paper.pdf},
 volume = {28},
 year = {2015}
}

@article{Ikonomov2020RobustOM,
  title={Robust Optimisation Monte Carlo},
  author={Borislav Ikonomov and Michael U. Gutmann},
  journal={ArXiv},
  year={2020},
  volume={abs/1904.00670}
}

@misc{molnar2020interpretable,
      title={Interpretable Machine Learning -- A Brief History, State-of-the-Art and Challenges},
      author={Christoph Molnar and Giuseppe Casalicchio and Bernd Bischl},
      year={2020},
      eprint={2010.09337},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}


@article{JMLR:v20:18-760,
  author  = {Aaron Fisher and Cynthia Rudin and Francesca Dominici},
  title   = {All Models are Wrong, but Many are Useful: Learning a Variable's Importance by Studying an Entire Class of Prediction Models Simultaneously},
  journal = {Journal of Machine Learning Research},
  year    = {2019},
  volume  = {20},
  number  = {177},
  pages   = {1-81},
  url     = {http://jmlr.org/papers/v20/18-760.html}
}

@misc{watson2021testing,
      title={Testing Conditional Independence in Supervised Learning Algorithms},
      author={David S. Watson and Marvin N. Wright},
      year={2021},
      eprint={1901.09917},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}

@misc{fabi2020,
      title={On Feature Relevance Uncertainty: A Monte Carlo Dropout Sampling Approach},
      author={Kai Fabi, Jonas Schneider},
      year={2020}}

@misc{williamson2020efficient,
      title={Efficient nonparametric statistical inference on population feature importance using Shapley values},
      author={Brian D. Williamson and Jean Feng},
      year={2020},
      eprint={2006.09481},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}

@article {Cranmer30055,
  author = {Cranmer, Kyle and Brehmer, Johann and Louppe, Gilles},
  title = {The frontier of simulation-based inference},
  volume = {117},
  number = {48},
  pages = {30055--30062},
  year = {2020},
  doi = {10.1073/pnas.1912789117},
  publisher = {National Academy of Sciences},
  abstract = {Many domains of science have developed complex simulations to describe phenomena of interest. While these simulations provide high-fidelity models, they are poorly suited for inference and lead to challenging inverse problems. We review the rapidly developing field of simulation-based inference and identify the forces giving additional momentum to the field. Finally, we describe how the frontier is expanding so that a broad audience can appreciate the profound influence these developments may have on science.There are no data associated with this paper.},
  issn = {0027-8424},
  URL = {https://www.pnas.org/content/117/48/30055},
  eprint = {https://www.pnas.org/content/117/48/30055.full.pdf},
  journal = {Proceedings of the National Academy of Sciences}
}